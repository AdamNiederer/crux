== Schema

*Note: in
https://en.wikipedia.org/wiki/Resource_Description_Framework[RDF], a
triple is made up of Subject Predicate Object, in Datomic the same thing
is called Entity Attribute Value.*

=== Triples, Documents and Property Graphs

Crux will deal with entities as either a triples or documents. The
identifier in the subject position in the triple represents its entity.
In a document store, each document would be represented as versions of
this same entity. In a triple store the document is implicit, being all
predicates reachable from an entity.

The triples, or the properties of the documents, can be connected to
other entities in a graph. For more about this, see
link:query.md[query].

One reason to use documents and not triples, is that triples are really
an implementation detail, and users are likely to think about distinct
versions of entities, like when using the map form in Datomic. When
allowing access to the triples themselves, the user can create a new
version of an entity ``by mistake'' without seeing the full state of the
resulting entity.

The triples will further need at least bitemporal query support, see
link:bitemp.md[bitemp] and the ability to build various forms of
retention and provenance models on top of the raw data, see
link:retention.md[retention].

This idea of documents above is close to the main other graph model,
apart from triples like in RDF, Property Graphs, see the relevant
documentation for
http://tinkerpop.apache.org/docs/current/reference/#intro[TinkerPop] and
https://neo4j.com/developer/graph-database/#property-graph[Neo4J], this
explanation is taken from the latter:

....
*Nodes* are the entities in the graph. They can hold any number of
attributes (key-value-pairs) called properties. Nodes can be
tagged with labels representing their different roles in your
domain.

*Relationships* provide directed, named, semantically relevant
connections between two node-entities (eg Employee WORKS_FOR
Company). A relationship always has a direction, a type, a start
node, and an end node. Like nodes, relationships can also have
properties.
....

Nodes are also referred to as vertexes, and relationships as edges.
Labels can be seen as the (multiple) classes an entity is an instance of
(not to be confused with labels of RDF N-quads, which are sub-graph
names). Properties are used for both attributes and meta data.

As nodes are entities which can have any number of properties, they can
be seen as documents, while relationships are similar to indexed
properties linking documents together. When using triples relationships
are predicates (attributes in Datomic), which cannot have properties of
their own (per instance). This must be modelled by introducing an
indirect entity.

*Triples are the most expressive model, but documents easier to reason
about for the user.*

*Note: we’re not talking about large binary documents here, just
different ways of reasoning about entities.*

* https://arxiv.org/abs/1802.07693[RStore: A Distributed Multi-version
Document Store]
* https://neo4j.com/blog/rdf-triple-store-vs-labeled-property-graph-difference/[RDF
Triple Stores vs. Labeled Property Graphs: What’s the Difference?]

=== Scalar Types and Indexing

The scalar types can be assumed to be normal values or references to
other entities. References to entities outside the store could also be
considered. In RDF, references are always some form of URI.

The data model can in the simplest case treat everything as bytes, and
not have any specific knowledge of different data types, and index all
attributes in a
https://redis.io/topics/indexes#representing-and-querying-graphs-using-an-hexastore[Hexastore]
style. More likely the schema will know at least of the URI or
references to other entities, as indexing all 6 permutations of each
triple takes up lot of space.

The scalar data types can further be modelled closely on Datomic and the
EDN data model, or say XML Schema to stay closer to RDF. Most likely we
want support for range queries across types supporting it.

Most likely we want to keep the core data binary and the way its dealt
with and indexed handled by an extensible interface so the user can add
their own types.

=== Non-scalar Types

In Datomic one can have an attribute with cardinality many, which
effectively makes it behave like a set, allowing multiple triples at the
same entity/attribute. This is problematic for various reasons. For
example, you need to explicitly remove all elements of the set if you
want to replace it. Another issue is that you cannot easily support
order to model lists. In triple stores there are ways to work around
this problem, but usually not in an elegant way.

In a document store, simple container data types, like lists, sets,
maps, and even nested component types, can be more easier defined and
reasoned about. A new version of a document always represent the entire
state. The underlying implementation can then choose to use deltas or
triples to model this.

Another issue with predicates that have multiple values, is that it
complicates indexing (and hence queries) in a bitemporal setting, as one
need to ensure that source and target of a reference are visible at the
same time. This can be mitigated by explicitly adding explicit
retractions to the index but this can double the index size, see
link:bitemp.md[bitemp] for more about this.

=== CRDTs

One option is to allow the underlying store directly support
https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type[conflict-free
replicated data types] to allow scaling without locks, while still
provide strong eventual consistency using a model that is possible to
reason about predictably for the user. This support would be built into
the types of the schema itself. See link:transactions.md[transactions]
for more about this.

* https://blog.acolyer.org/2018/03/27/anna-a-kvs-for-any-scale/[Anna: A
KVS for any scale]
* http://db.cs.berkeley.edu/papers/socc12-blooml.pdf[Logic and Lattices
for Distributed Programming]
* https://github.com/automerge/automerge[Automerge: A JSON-like data
structure that can be modified concurrently by different users, and
merged again automatically.]
* https://arxiv.org/abs/1710.04469[Pure Operation-Based Replicated Data
Types]

=== Additive Schema

One option, is to like MongoDB or Elasticsearch, allow usage without
having to explicitly define the schema upfront. In Mongo one still needs
to specify which fields needs to be indexed and how. And in
Elasticsearch, one also need to define the schema for anything but
trivial usage. In both cases you can still have parts of your documents
that are undefined from a query POV, and simply ``there''.

Datomic requires a stricter schema, as does RDF, as any entity referred
to, predicates in RDF are also themselves entities, similar to how in
Datomic the attribute is defined in the schema.

We have to assume that data evolves fast, and that it will be hard to
properly predict all data that can be written into the store, and all
the versions of the schema. Hence, having a defined schema complicates
matters, as this itself then also needs to evolve, vast data migrated
etc. For these reasons, one needs either a write once, additive only,
schema, or make the schema implicit.

=== Implicit Indexes

The schema exists for two different reasons, to allow the user reason
about the data, and ensure it adheres to the type system, but also
simply to help the query engine index things intelligently.

The indexes themselves are implicit in the queries done, but one cannot
wait until the last minute to index vast quantities of data, so the
easiest middle ground is to keep the schema at a minimum, but be
explicit about what is indexed and how. This can be done on value type
level, and not necessarily by defining an index for each predicate. That
is, certain types automatically gets indexed, but we don’t care about
what name they have.
