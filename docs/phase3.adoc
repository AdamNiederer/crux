# Crux Core - Phase 3 DRAFT

As Crux will now be live and open source, there will be a number of
activities going forward relating to having launched the product. This
document explicitly doesn't cover that, but is looking at the next big
core engineering areas. It does also not cover ops or cloud. I don't
expect us to touch on all of these during Phase 3. We might make
progress on maybe 2 or 3.

None of this is set it stone, it's a conversation starter. I've likely
missed large areas that do interest people.


### Matrix and Index Storage.

At CruxConf we almost decided to go ahead and push for having some
version of this by launch, but then decided to hold off. If we feel
that query performance is the most pressing concern, this is still an
area we should go ahead with.

As the indexes will work differently it could also open up to allowing
them to be stored outside of the nodes and shared between them, likely
in a distributed object store of some form. The query node will still
need the top level root index as this requires seeks.

This could allow us to move away from the KV stores, have our own
memory mapping or disk backend and potentially use succinct data
structures and other things, but it doesn't necessarily imply it.

#### Pros
* Speed.
* Likely less code.
* Further unbundled, can simplify storage and make the query engine
  more layered.

##### Cons
* No external new features apart from speed.
* Porting the existing query engine.
* Some unknowns, scope needs to be managed.
* Joins and potentially the entire result will need to fit into
  memory.


### Data Explorer.

We've noted the need for this. This isn't necessarily a core activity
though, but I except core engineering time being spent on it due to
its importance for making Crux more usable in practice.

#### Pros
* Shared tooling between Crux projects.
* Can help demo and sell Crux.
* Will help debugging.
* Value add to Crux.
* It would be an advanced Crux application we dog food.

#### Cons
* Scope is not well defined.
* Takes engineering time away from the core team.
* Needs someone else to drive it.


### Aggregation / Time Series.

Aggregation decorators are in the works. A temporal database sets the
expectation of having some story around time series data.

#### Pros
* Part of this can be done outside the core, but likely needs guiding
  by the core team.
* Opens up new areas, ticks the feature matrix.

#### Cons
* Doing this well would require a different architecture than what we
  have. We can try to take some of this into account when moving to
  Matrix, but that does in theory make it worse for this use case.
* We might spend time trying to compete in an area we can't.


### Real Bitemporal Queries.

Crux currently support point-in-time and limited history and history
range queries. In many bitemporal papers they go far beyond this
allowing for more complex queries across both time lines.

#### Pros
* Opens up far more auditing capability.
* Can do a better claim of being a "bitemporal" data store.
* Z Curve index opens up this a bit.

#### Cons
* Hard to reason about and adapt queries for.
* Will likely take a lot of time to get right compared to actual usage
  of the advanced bitemporal features.


### Sharding.

Classic requirement that will keep coming up. My hunch is that it
won't be needed in practice quite yet.

#### Pros
* Query nodes will need less disk.
* The easy version of this is simply assigning and managing document
  partitions intelligently.

#### Cons
* Complicates Crux.
* Need more real world Kafka usage to see how it will be done.
* Different architecture sharing index chunks might circumvent this,
  which needs to be taken into account.
* The simple version above needs more complexity and "virtual
  partitions" to allow re-sharding.


### Subscriptions.

Another early requirement. Blurs the line betweem Crux, stream
processing and rule engines a bit.

#### Pros
* Opens up a world of possibilities.
* Simple versions of this can be built around the transaction log and
  re-running queries.
* Can potentially use differential dataflow in an unbundled way as
  long as our log provides enough information.

#### Cons
* Modelling it into the core would be very intrusive. Could
  potentially be done when we introduce matrix, but it's an orthogonal
  problem.
* Using dataflow might lead to two different query engines with subtle
  differences unless we move it to the core.
* Needs us to think properly about how we related streaming, which
  like times series might lead to taking on too much scope in Crux, or
  taking on areas we don't really understand.


### Transaction Functions / Event Sourcing.

Slightly related to subscriptions. Can enable rule engine and
declarative programming on top of Crux itself.

#### Pros
* A lot of exciting possibilities.
* Likely to be some low-hanging fruit.
* Could lead to a Dedalus style programming model where you implement
  parts of your system in Crux's Datalog directly. A rule engine.

#### Cons
* Not many, but needs to balanced with other requirements.
* Trying to turn Crux into a rule engine might derail it from its
  primary bitemporal purpose.
* Transaction functions needs to be constrained and managed in various
  ways. Should be possible to evict.


### Non-JVM Core.

The non-decorator parts of Crux could be rewritten in another
language, most likely Rust, for both speed and memory safety.

The core of Crux is using UnsafeBuffers and JNR and is often fighting
Clojure and to a lesser extent the JVM to do things that would be
comparatively straight forward in the right language.

#### Pros
* Right tool for the job.
* Control over speed. Opens up for SIMD and vectorization. Potentially
  no GC. Better interaction with native libraries.
* Better memory safety if using Rust or similar language than when
  using sun.misc.Unsafe.
* Potential to be used as a library beyond the JVM world.

#### Cons
* Would still need to be embedded into Crux unless we rewrite the
  entire thing, which isn't necessarily a good idea unless we find the
  right boundaries, as we want to keep the benefit of Clojure in the
  higher layers.
* While Rust is the likely candidate, others might be more suitable in
  practice, so we need to spend time choosing the right tool.
* Will take time. We're not experts in these languages.
* We also need to understand their ecosystem, and how to deploy and
  debug such languages and also how to manage them operationally.
* The feedback loop and ability to iterate is lower, so more likely to
  go stale.

The language needs to be fast, have zero or low-cost interaction with
C libraries, and make managing memory easy, correct and cheap. No GC
is preferable, but not a strict requirement. It also needs to be easy
to call from Clojure and Java over JNI/JNR.

It should preferably be easy to work with and have reasonable feedback
loops and compilation times.

Alternatives to Rust could maybe be Common Lisp, Ada, OCaml, D or even
C itself combined with the right verification tools. We also have Java
on Graal, and could double down on using native images.

Second tier languages that might also be worth considering are Go and
Haskell, but they lack some of the desired requirements.

Take this breakdown with a pinch of salt, it's not been extensively
researched and apart from Go, C and Java I only have limited exposure
(but some) to all of these. Part of it is also subjective of course:

##### Rust

###### Pros
* A lot of momentum.
* Has all the capabilities.
* We know it would work.

###### Cons
* Slow compilation.
* Verbose type system.
* Somewhat complicated to manage lifetimes.

##### Common Lisp

###### Pros
* It's a Lisp. Emacs friendly.
* It would likely work well.
* Mature ecosystem.
* Fast mature implementations.
* Dialects like Clasp has low-cost C interop as part of their
  motivation.

###### Cons
* GC, dynamic typing.
* Huge language.
* Stale community.
* Might force dropping down to C for some things.

##### Ada

###### Pros
* Seems to tick all the boxes.
* Easy to read.
* Extremely proven and safe.
* SPARK subset can do partial verification.

###### Cons
* No current momentum outside its niches.
* Not even a modern package manager.
* Pascal-like syntax is nice to read, but verbose.
* SPARK and other parts are under real GPL if one doesn't pay.
* SIMD and lower level things still might require C.

##### OCaml

###### Pros
* Functional, mature, fast.
* Has good C interface.
* Some momentum.
* Used in industry.

###### Cons
* Still quite high level, might force dropping down to C.
* Has GC.

##### D

###### Pros
* Mature.
* Can choose subset to match need.
* Optional GC.
* Great C interface.

###### Cons
* Somewhat stale.
* It never took off properly.

##### C

###### Pros
* Almost exactly what you want, but without its problems.
* Great C interface by definition.
* No GC. No anything.
* Pragmatic. Simple.
* Speed, SIMD.

###### Cons
* Zero safety without verification or extensions.
* Quite verbose.
* Hard to write well.
* Code grows quickly.
* Package management is a mess.
* Requires some form of verification or extension to be a realistic
  alternative.

##### Go

###### Pros
* A lot of momentum.
* Good tooling.
* Used a lot in our space.
* Nice type system.

###### Cons
* GC.
* Not zero cost C interface, has its own ABI.
* Looks like a lower level language than it actually is.

##### Haskell

###### Pros
* Fast.
* Good C interface.

###### Cons
* Complex type system.
* Hard to read.
* Not a good fit, not necessarily much lower-level than Clojure.
* Low-level code is hard to fit into the type system.

##### Java with Native Image

###### Pros
* We are almost there.
* We know it well.
* Fast C interface inside the native image.

###### Cons
* Somewhat contrived as an option.
* Still relies on GC.
* Doesn't help with memory management of off heap memory.
* Partial solution, still requires C.
